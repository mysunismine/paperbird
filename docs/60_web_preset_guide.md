# Инструкция по созданию JSON-пресетов для веб-парсера Paperbird

Эта памятка описывает структуру пресета и обязательные поля, чтобы можно было оперативно объяснить требования ChatGPT (или другой LLM) и получить корректный JSON. Предполагаемый сценарий: вы отправляете модельке эту инструкцию, ссылку на сайт и список тегов/разделов, а в ответ получаете готовый пресет, который можно импортировать в Paperbird.

## 1. Общие сведения

Пресеты хранятся в поле `Source.web_preset_snapshot` и описывают полный цикл парсинга:
- как находить карточки новостей (list page);
- как извлекать контент со страницы статьи (article page);
- как нормализовать, очищать или отбрасывать элементы.

JSON должен быть валидным и соответствовать схеме (см. `projects/services/web_preset_registry.py`). Версия схемы на текущий момент — `1`.

## 2. Обязательные поля

| Поле        | Тип     | Описание                                                                 |
|-------------|---------|--------------------------------------------------------------------------|
| `name`      | string  | Уникальное машинное имя (латиница + `_`).                                |
| `version`   | string  | Версия пресета (`"1.0.0"` или семвер).                                   |
| `match`     | object  | Определяет, на какие домены распространяется пресет (см. ниже).          |
| `fetch`     | object  | Настройки HTTP (таймаут, заголовки, rate limit).                         |
| `list_page` | object  | Схема поиска карточек (селекторы списка, пагинация, фильтры).            |
| `article_page` | object | Как извлекать заголовок, текст, изображения, дату и метаданные.       |

### 2.1 `match`
```json
"match": {
  "domains": ["example.com", "www.example.com"]
}
```
Можно добавить `start_urls`, `deny_patterns`, но домены обязательны.

### 2.2 `fetch`
```json
"fetch": {
  "timeout_sec": 10,
  "headers": {
    "User-Agent": "PaperbirdWebCollector/1.0 (+https://paperbird.ai)"
  },
  "rate_limit_rps": 0.5
}
```
`rate_limit_rps` задаёт ограничение запросов в секунду (0 — без лимита).

## 3. Конфигурация списка (`list_page`)

```json
"list_page": {
  "seeds": ["https://example.com/news"],
  "selectors": {
    "items": "article.card",
    "url": "a@href",
    "title": "a@text",
    "published_at": ".date@text"
  },
  "filters": {
    "include": ["технологии", "цифровизация"],
    "exclude": ["реклама"]
  },
  "pagination": {
    "type": "next_button",
    "selector": "a.next",
    "max_pages": 3
  }
}
```

- `items` — CSS-селектор контейнера карточки.
- `url`, `title`, `published_at` поддерживают синтаксис `selector@attr` (`@text` для текстового узла).
- `filters` (опционально) позволяют отбросить карточки по ключевым словам в заголовке.
- `pagination` может быть `none`, `next_button`, `param_increment`, `custom`. Для большинства сайтов хватает `next_button` + `max_pages`.

## 4. Конфигурация статьи (`article_page`)

```json
"article_page": {
  "selectors": {
    "title": "h1.headline@text",
    "content": "div.article-body",
    "images": "div.article-body img@src*",
    "published_at": "time@datetime"
  },
  "cleanup": {
    "remove": ["div.ad", "aside"],
    "unwrap": ["figure", "picture"]
  },
  "normalize": {
    "html_to_md": true,
    "strip_whitespace": true,
    "fix_relative_urls": true
  },
  "metadata": {
    "author": ".author@text",
    "tags": "ul.tags li@text*"
  }
}
```

- `content` — основной контейнер текста (можно использовать `.article__content` и т.п.).
- `images` с `@src*` собирает все ссылки. Минимум одна картинка — желательно.
- `cleanup.remove` — селекторы, которые нужно удалить (реклама, подписки).
- `cleanup.unwrap` — теги, которые нужно раскрыть (убрать контейнер, оставить содержимое).
- `normalize.html_to_md` — отдавать Markdown (Paperbird автоматически сохранит HTML и MD).
- `metadata` — произвольный словарь дополнительных полей (попадает в `external_metadata`).

## 5. Дополнительные советы

1. **Указывайте абсолютные URL.** Если сайт отдаёт относительные пути, используйте `normalize.fix_relative_urls`.
2. **Дата и время.** Желательно вытягивать ISO 8601 (`<time datetime="2024-11-05T10:00:00+03:00">`) или текст, который можно распарсить (`parse_datetime` обработает большинство форматов).
3. **Фильтры.** Если у сайта много рубрик, попросите ChatGPT добавить `filters.include` по нужным тематикам.
4. **Изображения.** В `images_manifest` можно хранить список объектов: `{"url": "...", "caption": "..."}`. Если нужны подписи — явно попросите модель об этом.
5. **Проверка.** После генерации попробуйте импортировать JSON через форму источника (`Настройки проекта → Источники → Импорт пресета`), чтобы валидатор подсказал ошибки.

## 6. Пример промта для ChatGPT

```
Вот инструкция по формату пресетов (ниже). Создай JSON-пресет для Paperbird:
- сайт: https://pln-pskov.ru/
- нужно парсить разделы "Новости", "Политика"
- отбрось материалы с пометкой "Реклама"
- сохрани изображения и даты публикации
(вставьте сюда текст инструкции)
```

Модель вернёт готовый JSON, который можно сразу импортировать.

## 7. Отладка

- Используйте `python manage.py shell` и `WebPresetValidator` для проверки JSON без UI.
- Для локальных тестов существует management-команда или worker `collect_project_web_sources_task`, которые читают `web_preset_snapshot`.

---

Эту инструкцию рекомендуется держать под рукой в `docs/60_web_preset_guide.md` и подкладывать в каждый запрос к ChatGPT вместе с конкретными требованиями по сайту (URL, рубрики, ограничения). Так минимизируются правки после генерации пресета.
